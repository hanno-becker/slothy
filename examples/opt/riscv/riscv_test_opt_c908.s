.macro load_coeffs poly, len, wordLen
  lw s0,  \len*\wordLen*0(\poly)
  lw s1,  \len*\wordLen*1(\poly)
  lw s2,  \len*\wordLen*2(\poly)
  lw s3,  \len*\wordLen*3(\poly)
  lw s4,  \len*\wordLen*4(\poly)
  lw s5,  \len*\wordLen*5(\poly)
  lw s6,  \len*\wordLen*6(\poly)
  lw s7,  \len*\wordLen*7(\poly)
  lw s8,  \len*\wordLen*8(\poly)
  lw s9,  \len*\wordLen*9(\poly)
  lw s10, \len*\wordLen*10(\poly)
  lw s11, \len*\wordLen*11(\poly)
  lw a2,  \len*\wordLen*12(\poly)
  lw a3,  \len*\wordLen*13(\poly)
  lw a4,  \len*\wordLen*14(\poly)
  lw a5,  \len*\wordLen*15(\poly)
.endm

// r <- a*b*(-2^{-64}) mod+- q
// q32: q<<32; bqinv: b*qinv
.macro plant_mul_const q32, bqinv, a, r
    mul  \r, \a, \bqinv
    srai \r, \r, 32
    addi \r, \r, 256
    mulh \r, \r, \q32
.endm

// each layer increases coefficients by 0.5q; In ct_bfu, twiddle and tmp can be reused because each twiddle is only used once. The gs_bfu cannot.
.macro ct_bfu coeff0, coeff1, twiddle, q, tmp
  plant_mul_const \q, \twiddle, \coeff1, \tmp
  sub \coeff1, \coeff0, \tmp
  add \coeff0, \coeff0, \tmp
.endm


.equ q,    8380417
.equ q32,  0x7fe00100000000               // q << 32
.equ qinv, 0x180a406003802001             // q^-1 mod 2^64
.equ plantconst, 0x200801c0602            // (((-2**64) % q) * qinv) % (2**64)
.equ plantconst2, 0xb7b9f10ccf939804      // (((-2**64) % q) * ((-2**64) % q) * qinv) % (2**64)

.global ntt_8l_rv64im_opt_c908
.align 2
ntt_8l_rv64im_opt_c908:
  addi sp, sp, -8*15
  li a6, q32          // q<<32
  addi a0, a0, 16*4   // poly[16]
  addi gp, x0, 15     // loop
  ld t0, 0*8(a1)
  ld t1, 1*8(a1)
  ld t2, 2*8(a1)
  ld t3, 3*8(a1)
  ld t4, 4*8(a1)
  ld t5, 5*8(a1)
  ld t6, 6*8(a1)
  ld tp, 7*8(a1)
  ld ra, 8*8(a1)

  // LAYER 1+2+3+4
  ntt_8l_rv64im_loop1:
        start_label:
                                    // Instructions:    29
                                    // Expected cycles: 18
                                    // Expected IPC:    1.61
                                    //
                                    // Cycle bound:     18.0
                                    // IPC bound:       1.61
                                    //
                                    // Wall time:     177.80s
                                    // User time:     177.80s
                                    //
                                    // ----- cycle (expected) ------>
                                    // 0                        25
                                    // |------------------------|----
        addi x10, x10, -4           // *.............................
        lw x18, 16*4*2(x10)         // .*............................
        lw x15, 16*4*9(x10)         // ..*...........................
        lw x8, 16*4*0(x10)          // ...*..........................
        lw x13, 16*4*8(x10)         // ....*.........................
        mul x12, x15, x5            // ....*.........................
        lw x21, 16*4*5(x10)         // .....*........................
        mul x14, x13, x5            // ......*.......................
        lw x27, 16*4*11(x10)        // ......*.......................
        lw x15, 16*4*15(x10)        // .......*......................
        lw x22, 16*4*6(x10)         // ........*.....................
        srai x12, x12, 32           // ........*.....................
        addi x12, x12, 256          // .........*....................
        lw x9, 16*4*1(x10)          // .........*....................
        mulh x17, x12, x16          // ..........*...................
        srai x24, x14, 32           // ..........*...................
        addi x20, x24, 256          // ...........*..................
        lw x26, 16*4*10(x10)        // ...........*..................
        mulh x19, x20, x16          // ............*.................
        lw x14, 16*4*14(x10)        // ............*.................
        lw x20, 16*4*4(x10)         // .............*................
        lw x23, 16*4*7(x10)         // ..............*...............
        sub x25, x9, x17            // ..............*...............
        add x9, x9, x17             // ...............*..............
        lw x12, 16*4*12(x10)        // ...............*..............
        lw x13, 16*4*13(x10)        // ................*.............
        sub x24, x8, x19            // ................*.............
        add x8, x8, x19             // .................*............
        lw x19, 16*4*3(x10)         // .................*............

                                      // ------ cycle (expected) ------>
                                      // 0                        25
                                      // |------------------------|-----
        // addi x10, x10, -4          // *..............................
        // lw x8,  16*4*0(x10)        // ...*...........................
        // lw x9,  16*4*1(x10)        // .........*.....................
        // lw x18,  16*4*2(x10)       // .*.............................
        // lw x19,  16*4*3(x10)       // .................*.............
        // lw x20,  16*4*4(x10)       // .............*.................
        // lw x21,  16*4*5(x10)       // .....*.........................
        // lw x22,  16*4*6(x10)       // ........*......................
        // lw x23,  16*4*7(x10)       // ..............*................
        // lw x24,  16*4*8(x10)       // ....*..........................
        // lw x25,  16*4*9(x10)       // ..*............................
        // lw x26, 16*4*10(x10)       // ...........*...................
        // lw x27, 16*4*11(x10)       // ......*........................
        // lw x12,  16*4*12(x10)      // ...............*...............
        // lw x13,  16*4*13(x10)      // ................*..............
        // lw x14,  16*4*14(x10)      // ............*..................
        // lw x15,  16*4*15(x10)      // .......*.......................
        // mul  x17, x24, x5          // ......*........................
        // srai x17, x17, 32          // ..........*....................
        // addi x17, x17, 256         // ...........*...................
        // mulh x17, x17, x16         // ............*..................
        // sub x24, x8, x17           // ................*..............
        // add x8, x8, x17            // .................*.............
        // mul  x17, x25, x5          // ....*..........................
        // srai x17, x17, 32          // ........*......................
        // addi x17, x17, 256         // .........*.....................
        // mulh x17, x17, x16         // ..........*....................
        // sub x25, x9, x17           // ..............*................
        // add x9, x9, x17            // ...............*...............

        end_label:

  ret


