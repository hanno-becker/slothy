///
// github.com/Ji-Peng/PQRV/blob/2463d15ba6c49d05d45ff427b72646e038c860da/ntt/dilithium/ntt_8l_singleissue_plant_rv64im.S /// Code from https:
///
/// The MIT license, the text of which is below, applies to PQRV in general.
// github.com/pq-crystals/kyber and https: // github.com/pq-crystals/dilithium. /// We have reused public-domain code from the following repositories: https:
///
/// Copyright (c) 2024 Jipeng Zhang (jp-zhang@outlook.com)
/// SPDX-License-Identifier: MIT
///
/// Permission is hereby granted, free of charge, to any person obtaining a copy
/// of this software and associated documentation files (the "Software"), to deal
/// in the Software without restriction, including without limitation the rights
/// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
/// copies of the Software, and to permit persons to whom the Software is
/// furnished to do so, subject to the following conditions:
///
/// The above copyright notice and this permission notice shall be included in all
/// copies or substantial portions of the Software.
///
/// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
/// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
/// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
/// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
/// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
/// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
/// SOFTWARE.
///

.macro load_coeffs poly, len, wordLen
  lw s0,  \len*\wordLen*0(\poly)
  lw s1,  \len*\wordLen*1(\poly)
  lw s2,  \len*\wordLen*2(\poly)
  lw s3,  \len*\wordLen*3(\poly)
  lw s4,  \len*\wordLen*4(\poly)
  lw s5,  \len*\wordLen*5(\poly)
  lw s6,  \len*\wordLen*6(\poly)
  lw s7,  \len*\wordLen*7(\poly)
  lw s8,  \len*\wordLen*8(\poly)
  lw s9,  \len*\wordLen*9(\poly)
  lw s10, \len*\wordLen*10(\poly)
  lw s11, \len*\wordLen*11(\poly)
  lw a2,  \len*\wordLen*12(\poly)
  lw a3,  \len*\wordLen*13(\poly)
  lw a4,  \len*\wordLen*14(\poly)
  lw a5,  \len*\wordLen*15(\poly)
.endm

.macro store_coeffs poly, len, wordLen
  sw s0,  \len*\wordLen*0(\poly)
  sw s1,  \len*\wordLen*1(\poly)
  sw s2,  \len*\wordLen*2(\poly)
  sw s3,  \len*\wordLen*3(\poly)
  sw s4,  \len*\wordLen*4(\poly)
  sw s5,  \len*\wordLen*5(\poly)
  sw s6,  \len*\wordLen*6(\poly)
  sw s7,  \len*\wordLen*7(\poly)
  sw s8,  \len*\wordLen*8(\poly)
  sw s9,  \len*\wordLen*9(\poly)
  sw s10, \len*\wordLen*10(\poly)
  sw s11, \len*\wordLen*11(\poly)
  sw a2,  \len*\wordLen*12(\poly)
  sw a3,  \len*\wordLen*13(\poly)
  sw a4,  \len*\wordLen*14(\poly)
  sw a5,  \len*\wordLen*15(\poly)
.endm

.macro save_regs
  sd s0,  0*8(sp)
  sd s1,  1*8(sp)
  sd s2,  2*8(sp)
  sd s3,  3*8(sp)
  sd s4,  4*8(sp)
  sd s5,  5*8(sp)
  sd s6,  6*8(sp)
  sd s7,  7*8(sp)
  sd s8,  8*8(sp)
  sd s9,  9*8(sp)
  sd s10, 10*8(sp)
  sd s11, 11*8(sp)
  sd gp,  12*8(sp)
  sd tp,  13*8(sp)
  sd ra,  14*8(sp)
.endm

.macro restore_regs
  ld s0,  0*8(sp)
  ld s1,  1*8(sp)
  ld s2,  2*8(sp)
  ld s3,  3*8(sp)
  ld s4,  4*8(sp)
  ld s5,  5*8(sp)
  ld s6,  6*8(sp)
  ld s7,  7*8(sp)
  ld s8,  8*8(sp)
  ld s9,  9*8(sp)
  ld s10, 10*8(sp)
  ld s11, 11*8(sp)
  ld gp,  12*8(sp)
  ld tp,  13*8(sp)
  ld ra,  14*8(sp)
.endm

// a <- a*b*(-2^{-64}) mod+- q
// q32: q<<32; bqinv: b*qinv
.macro plant_mul_const_inplace q32, bqinv, a
  mul  \a, \a, \bqinv
  srai \a, \a, 32
  addi \a, \a, 256
  mulh \a, \a, \q32
.endm

// r <- a*b*(-2^{-64}) mod+- q
// q32: q<<32; bqinv: b*qinv
.macro plant_mul_const q32, bqinv, a, r
    mul  \r, \a, \bqinv
    srai \r, \r, 32
    addi \r, \r, 256
    mulh \r, \r, \q32
.endm

// each layer increases coefficients by 0.5q; In ct_bfu, twiddle and tmp can be reused because each twiddle is only used once. The gs_bfu cannot.
.macro ct_bfu coeff0, coeff1, twiddle, q, tmp
  plant_mul_const \q, \twiddle, \coeff1, \tmp
  sub \coeff1, \coeff0, \tmp
  add \coeff0, \coeff0, \tmp
.endm

.macro gs_bfu coeff0, coeff1, twiddle, q, tmp
  sub \tmp, \coeff0, \coeff1
  add \coeff0, \coeff0, \coeff1
  plant_mul_const \q, \twiddle, \tmp, \coeff1
.endm

// in-place plantard reduction to a
// output \in (-0.5q, 0.5q); q32: q<<32
.macro plant_red q32, qinv, a
  mul  \a, \a, \qinv
  srai \a, \a, 32
  addi \a, \a, 256
  mulh \a, \a, \q32
.endm

.macro plant_red_x4 q32, qinv, a_0, a_1, a_2, a_3
  mul  \a_0, \a_0, \qinv
  mul  \a_1, \a_1, \qinv
  mul  \a_2, \a_2, \qinv
  mul  \a_3, \a_3, \qinv
  srai \a_0, \a_0, 32
  srai \a_1, \a_1, 32
  srai \a_2, \a_2, 32
  srai \a_3, \a_3, 32
  addi \a_0, \a_0, 256
  addi \a_1, \a_1, 256
  addi \a_2, \a_2, 256
  addi \a_3, \a_3, 256
  mulh \a_0, \a_0, \q32
  mulh \a_1, \a_1, \q32
  mulh \a_2, \a_2, \q32
  mulh \a_3, \a_3, \q32
.endm

.equ q,    8380417
.equ q32,  0x7fe00100000000               // q << 32
.equ qinv, 0x180a406003802001             // q^-1 mod 2^64
.equ plantconst, 0x200801c0602            // (((-2**64) % q) * qinv) % (2**64)
.equ plantconst2, 0xb7b9f10ccf939804      // (((-2**64) % q) * ((-2**64) % q) * qinv) % (2**64)

// |input| < 0.5q; |output| < 4q
// API: a0: poly, a1: 64-bit twiddle ptr; a6: q<<32; a7: tmp, variable twiddle factors; gp: loop;
// s0-s11, a2-a5: 16 coeffs;
// 16+2+1+1=20 regs;
// 9 twiddle factors: can be preloaded; t0-t6, tp, ra.
.global ntt_8l_rv64im
.align 2
ntt_8l_rv64im:
  addi sp, sp, -8*15
  save_regs
  li a6, q32          // q<<32
  addi a0, a0, 16*4   // poly[16]
  addi gp, x0, 15     // loop
  ld t0, 0*8(a1)
  ld t1, 1*8(a1)
  ld t2, 2*8(a1)
  ld t3, 3*8(a1)
  ld t4, 4*8(a1)
  ld t5, 5*8(a1)
  ld t6, 6*8(a1)
  ld tp, 7*8(a1)
  ld ra, 8*8(a1)
  // LAYER 1+2+3+4
  ntt_8l_rv64im_loop1:
    addi a0, a0, -4
    load_coeffs a0, 16, 4
    // layer 1
        main_loop:
                                   // Instructions:    144
                                   // Expected cycles: 99
                                   // Expected IPC:    1.45
                                   //
                                   // Cycle bound:     99.0
                                   // IPC bound:       1.45
                                   //
                                   // Wall time:     123.28s
                                   // User time:     123.28s
                                   //
                                   // ---------------------------------------- cycle (expected) ---------------------------------------->
                                   // 0                        25                       50                       75
                                   // |------------------------|------------------------|------------------------|-----------------------
        mul x0, x13, x5            // *..................................................................................................
        mul x13, x14, x5           // ..*................................................................................................
        mul x17, x15, x5           // ....*..............................................................................................
        srai x0, x0, 32            // ....*..............................................................................................
        addi x0, x0, 256           // .....*.............................................................................................
        mulh x15, x0, x16          // ......*............................................................................................
        srai x0, x13, 32           // ......*............................................................................................
        addi x0, x0, 256           // .......*...........................................................................................
        mulh x0, x0, x16           // ........*..........................................................................................
        srai x13, x17, 32          // ........*..........................................................................................
        addi x13, x13, 256         // .........*.........................................................................................
        mulh x17, x13, x16         // ..........*........................................................................................
        add x14, x21, x15          // ..........*........................................................................................
        sub x15, x21, x15          // ...........*.......................................................................................
        mul x21, x27, x5           // ............*......................................................................................
        sub x13, x22, x0           // ............*......................................................................................
        add x0, x22, x0            // .............*.....................................................................................
        mul x22, x0, x6            // ..............*....................................................................................
        sub x27, x23, x17          // ..............*....................................................................................
        add x23, x23, x17          // ...............*...................................................................................
        srai x17, x21, 32          // ................*..................................................................................
        mul x23, x23, x6           // ................*..................................................................................
        addi x17, x17, 256         // .................*.................................................................................
        mulh x17, x17, x16         // ..................*................................................................................
        srai x0, x22, 32           // ..................*................................................................................
        addi x22, x0, 256          // ...................*...............................................................................
        mulh x22, x22, x16         // ....................*..............................................................................
        srai x23, x23, 32          // ....................*..............................................................................
        addi x21, x23, 256         // .....................*.............................................................................
        mulh x21, x21, x16         // ......................*............................................................................
        add x23, x19, x17          // ......................*............................................................................
        sub x17, x19, x17          // .......................*...........................................................................
        mul x25, x25, x5           // ........................*..........................................................................
        add x0, x23, x21           // ..........................*........................................................................
        mul x19, x14, x6           // ..........................*........................................................................
        sub x21, x23, x21          // ...........................*.......................................................................
        srai x25, x25, 32          // ............................*......................................................................
        mul x23, x21, x29          // ............................*......................................................................
        addi x21, x25, 256         // .............................*.....................................................................
        mulh x14, x21, x16         // ..............................*....................................................................
        srai x25, x19, 32          // ..............................*....................................................................
        addi x25, x25, 256         // ...............................*...................................................................
        mulh x19, x25, x16         // ................................*..................................................................
        srai x21, x23, 32          // ................................*..................................................................
        addi x21, x21, 256         // .................................*.................................................................
        add x25, x9, x14           // ..................................*................................................................
        mulh x23, x21, x16         // ..................................*................................................................
        sub x14, x9, x14           // ...................................*...............................................................
        mul x9, x26, x5            // ....................................*..............................................................
        sub x26, x25, x19          // ....................................*..............................................................
        mul x0, x0, x28            // ......................................*............................................................
        add x21, x26, x23          // ......................................*............................................................
        sub x23, x26, x23          // .......................................*...........................................................
        mul x26, x12, x5           // ........................................*..........................................................
        srai x12, x9, 32           // ........................................*..........................................................
        addi x12, x12, 256         // .........................................*.........................................................
        srai x0, x0, 32            // ..........................................*........................................................
        mulh x9, x12, x16          // ..........................................*........................................................
        add x25, x25, x19          // ...........................................*.......................................................
        addi x19, x0, 256          // ...........................................*.......................................................
        srai x0, x26, 32           // ............................................*......................................................
        mul x26, x15, x7           // ............................................*......................................................
        addi x0, x0, 256           // .............................................*.....................................................
        mulh x0, x0, x16           // ..............................................*....................................................
        add x12, x18, x9           // ..............................................*....................................................
        sub x15, x12, x22          // ...............................................*...................................................
        add x12, x12, x22          // ...............................................*...................................................
        srai x26, x26, 32          // ................................................*..................................................
        mul x22, x15, x29          // ................................................*..................................................
        addi x26, x26, 256         // .................................................*.................................................
        sub x15, x18, x9           // .................................................*.................................................
        mul x12, x12, x28          // ..................................................*................................................
        add x9, x20, x0            // ..................................................*................................................
        sub x0, x20, x0            // ...................................................*...............................................
        mul x20, x9, x6            // ....................................................*..............................................
        srai x22, x22, 32          // ....................................................*..............................................
        addi x9, x22, 256          // .....................................................*.............................................
        mul x18, x24, x5           // ......................................................*............................................
        srai x22, x12, 32          // ......................................................*............................................
        addi x22, x22, 256         // .......................................................*...........................................
        mulh x12, x22, x16         // ........................................................*..........................................
        srai x20, x20, 32          // ........................................................*..........................................
        addi x20, x20, 256         // .........................................................*.........................................
        mul x0, x0, x7             // ..........................................................*........................................
        srai x24, x18, 32          // ..........................................................*........................................
        addi x22, x24, 256         // ...........................................................*.......................................
        mulh x22, x22, x16         // ............................................................*......................................
        mulh x18, x20, x16         // ..............................................................*....................................
        srai x0, x0, 32            // ..............................................................*....................................
        addi x0, x0, 256           // ...............................................................*...................................
        sub x24, x8, x22           // ................................................................*..................................
        mul x13, x13, x7           // ................................................................*..................................
        add x20, x8, x22           // .................................................................*.................................
        mulh x22, x0, x16          // ..................................................................*................................
        add x8, x20, x18           // ..................................................................*................................
        sub x20, x20, x18          // ...................................................................*...............................
        mulh x9, x9, x16           // ....................................................................*..............................
        srai x18, x13, 32          // ....................................................................*..............................
        addi x13, x18, 256         // .....................................................................*.............................
        sub x18, x8, x12           // .....................................................................*.............................
        mulh x0, x13, x16          // ......................................................................*............................
        add x8, x8, x12            // ......................................................................*............................
        add x12, x24, x22          // .......................................................................*...........................
        sub x13, x24, x22          // ........................................................................*..........................
        mul x27, x27, x7           // ........................................................................*..........................
        sub x22, x20, x9           // .........................................................................*.........................
        add x20, x20, x9           // ..........................................................................*........................
        mulh x26, x26, x16         // ..........................................................................*........................
        add x24, x15, x0           // ...........................................................................*.......................
        sub x15, x15, x0           // ...........................................................................*.......................
        srai x0, x27, 32           // ............................................................................*......................
        mul x24, x24, x30          // ............................................................................*......................
        addi x0, x0, 256           // .............................................................................*.....................
        mul x27, x15, X<pc>        // ..............................................................................*....................
        srai x15, x24, 32          // ................................................................................*..................
        mulh x9, x0, x16           // ................................................................................*..................
        add x0, x14, x26           // .................................................................................*.................
        addi x24, x15, 256         // .................................................................................*.................
        srai x27, x27, 32          // ..................................................................................*................
        mulh x19, x19, x16         // ..................................................................................*................
        mulh x24, x24, x16         // ....................................................................................*..............
        sub x15, x17, x9           // ....................................................................................*..............
        add x17, x17, x9           // .....................................................................................*.............
        add x9, x25, x19           // ......................................................................................*............
        mul x15, x15, X<pc>        // ......................................................................................*............
        sub x19, x25, x19          // .......................................................................................*...........
        sub x25, x14, x26          // .......................................................................................*...........
        sub x26, x12, x24          // ........................................................................................*..........
        mul x17, x17, x30          // ........................................................................................*..........
        addi x27, x27, 256         // .........................................................................................*.........
        add x24, x12, x24          // .........................................................................................*.........
        mulh x14, x27, x16         // ..........................................................................................*........
        srai x15, x15, 32          // ..........................................................................................*........
        addi x15, x15, 256         // ...........................................................................................*.......
        srai x27, x17, 32          // ............................................................................................*......
        mulh x17, x15, x16         // ............................................................................................*......
        addi x27, x27, 256         // .............................................................................................*.....
        add x12, x13, x14          // ..............................................................................................*....
        mulh x27, x27, x16         // ..............................................................................................*....
        sub x15, x25, x17          // ................................................................................................*..
        sub x14, x13, x14          // ................................................................................................*..
        add x13, x25, x17          // .................................................................................................*.
        add x25, x0, x27           // ..................................................................................................*
        sub x27, x0, x27           // ..................................................................................................*

                                   // ---------------------------------------- cycle (expected) ---------------------------------------->
                                   // 0                        25                       50                       75
                                   // |------------------------|------------------------|------------------------|-----------------------
        // mul  x17, x24, x5       // ......................................................*............................................
        // srai x17, x17, 32       // ..........................................................*........................................
        // addi x17, x17, 256      // ...........................................................*.......................................
        // mulh x17, x17, x16      // ............................................................*......................................
        // sub x24, x8, x17        // ................................................................*..................................
        // add x8, x8, x17         // .................................................................*.................................
        // mul  x17, x25, x5       // ........................*..........................................................................
        // srai x17, x17, 32       // ............................*......................................................................
        // addi x17, x17, 256      // .............................*.....................................................................
        // mulh x17, x17, x16      // ..............................*....................................................................
        // sub x25, x9, x17        // ...................................*...............................................................
        // add x9, x9, x17         // ..................................*................................................................
        // mul  x17, x26, x5       // ....................................*..............................................................
        // srai x17, x17, 32       // ........................................*..........................................................
        // addi x17, x17, 256      // .........................................*.........................................................
        // mulh x17, x17, x16      // ..........................................*........................................................
        // sub x26, x18, x17       // .................................................*.................................................
        // add x18, x18, x17       // ..............................................*....................................................
        // mul  x17, x27, x5       // ............*......................................................................................
        // srai x17, x17, 32       // ................*..................................................................................
        // addi x17, x17, 256      // .................*.................................................................................
        // mulh x17, x17, x16      // ..................*................................................................................
        // sub x27, x19, x17       // .......................*...........................................................................
        // add x19, x19, x17       // ......................*............................................................................
        // mul  x17, x12, x5       // ........................................*..........................................................
        // srai x17, x17, 32       // ............................................*......................................................
        // addi x17, x17, 256      // .............................................*.....................................................
        // mulh x17, x17, x16      // ..............................................*....................................................
        // sub x12, x20, x17       // ...................................................*...............................................
        // add x20, x20, x17       // ..................................................*................................................
        // mul  x17, x13, x5       // *..................................................................................................
        // srai x17, x17, 32       // ....*..............................................................................................
        // addi x17, x17, 256      // .....*.............................................................................................
        // mulh x17, x17, x16      // ......*............................................................................................
        // sub x13, x21, x17       // ...........*.......................................................................................
        // add x21, x21, x17       // ..........*........................................................................................
        // mul  x17, x14, x5       // ..*................................................................................................
        // srai x17, x17, 32       // ......*............................................................................................
        // addi x17, x17, 256      // .......*...........................................................................................
        // mulh x17, x17, x16      // ........*..........................................................................................
        // sub x14, x22, x17       // ............*......................................................................................
        // add x22, x22, x17       // .............*.....................................................................................
        // mul  x17, x15, x5       // ....*..............................................................................................
        // srai x17, x17, 32       // ........*..........................................................................................
        // addi x17, x17, 256      // .........*.........................................................................................
        // mulh x17, x17, x16      // ..........*........................................................................................
        // sub x15, x23, x17       // ..............*....................................................................................
        // add x23, x23, x17       // ...............*...................................................................................
        // mul  x17, x20, x6       // ....................................................*..............................................
        // srai x17, x17, 32       // ........................................................*..........................................
        // addi x17, x17, 256      // .........................................................*.........................................
        // mulh x17, x17, x16      // ..............................................................*....................................
        // sub x20, x8, x17        // ...................................................................*...............................
        // add x8, x8, x17         // ..................................................................*................................
        // mul  x17, x21, x6       // ..........................*........................................................................
        // srai x17, x17, 32       // ..............................*....................................................................
        // addi x17, x17, 256      // ...............................*...................................................................
        // mulh x17, x17, x16      // ................................*..................................................................
        // sub x21, x9, x17        // ....................................*..............................................................
        // add x9, x9, x17         // ...........................................*.......................................................
        // mul  x17, x22, x6       // ..............*....................................................................................
        // srai x17, x17, 32       // ..................*................................................................................
        // addi x17, x17, 256      // ...................*...............................................................................
        // mulh x17, x17, x16      // ....................*..............................................................................
        // sub x22, x18, x17       // ...............................................*...................................................
        // add x18, x18, x17       // ...............................................*...................................................
        // mul  x17, x23, x6       // ................*..................................................................................
        // srai x17, x17, 32       // ....................*..............................................................................
        // addi x17, x17, 256      // .....................*.............................................................................
        // mulh x17, x17, x16      // ......................*............................................................................
        // sub x23, x19, x17       // ...........................*.......................................................................
        // add x19, x19, x17       // ..........................*........................................................................
        // mul  x17, x12, x7       // ..........................................................*........................................
        // srai x17, x17, 32       // ..............................................................*....................................
        // addi x17, x17, 256      // ...............................................................*...................................
        // mulh x17, x17, x16      // ..................................................................*................................
        // sub x12, x24, x17       // ........................................................................*..........................
        // add x24, x24, x17       // .......................................................................*...........................
        // mul  x17, x13, x7       // ............................................*......................................................
        // srai x17, x17, 32       // ................................................*..................................................
        // addi x17, x17, 256      // .................................................*.................................................
        // mulh x17, x17, x16      // ..........................................................................*........................
        // sub x13, x25, x17       // .......................................................................................*...........
        // add x25, x25, x17       // .................................................................................*.................
        // mul  x17, x14, x7       // ................................................................*..................................
        // srai x17, x17, 32       // ....................................................................*..............................
        // addi x17, x17, 256      // .....................................................................*.............................
        // mulh x17, x17, x16      // ......................................................................*............................
        // sub x14, x26, x17       // ...........................................................................*.......................
        // add x26, x26, x17       // ...........................................................................*.......................
        // mul  x17, x15, x7       // ........................................................................*..........................
        // srai x17, x17, 32       // ............................................................................*......................
        // addi x17, x17, 256      // .............................................................................*.....................
        // mulh x17, x17, x16      // ................................................................................*..................
        // sub x15, x27, x17       // ....................................................................................*..............
        // add x27, x27, x17       // .....................................................................................*.............
        // mul  x17, x18, x28      // ..................................................*................................................
        // srai x17, x17, 32       // ......................................................*............................................
        // addi x17, x17, 256      // .......................................................*...........................................
        // mulh x17, x17, x16      // ........................................................*..........................................
        // sub x18, x8, x17        // .....................................................................*.............................
        // add x8, x8, x17         // ......................................................................*............................
        // mul  x17, x19, x28      // ......................................*............................................................
        // srai x17, x17, 32       // ..........................................*........................................................
        // addi x17, x17, 256      // ...........................................*.......................................................
        // mulh x17, x17, x16      // ..................................................................................*................
        // sub x19, x9, x17        // .......................................................................................*...........
        // add x9, x9, x17         // ......................................................................................*............
        // mul  x17, x22, x29      // ................................................*..................................................
        // srai x17, x17, 32       // ....................................................*..............................................
        // addi x17, x17, 256      // .....................................................*.............................................
        // mulh x17, x17, x16      // ....................................................................*..............................
        // sub x22, x20, x17       // .........................................................................*.........................
        // add x20, x20, x17       // ..........................................................................*........................
        // mul  x17, x23, x29      // ............................*......................................................................
        // srai x17, x17, 32       // ................................*..................................................................
        // addi x17, x17, 256      // .................................*.................................................................
        // mulh x17, x17, x16      // ..................................*................................................................
        // sub x23, x21, x17       // .......................................*...........................................................
        // add x21, x21, x17       // ......................................*............................................................
        // mul  x17, x26, x30      // ............................................................................*......................
        // srai x17, x17, 32       // ................................................................................*..................
        // addi x17, x17, 256      // .................................................................................*.................
        // mulh x17, x17, x16      // ....................................................................................*..............
        // sub x26, x24, x17       // ........................................................................................*..........
        // add x24, x24, x17       // .........................................................................................*.........
        // mul  x17, x27, x30      // ........................................................................................*..........
        // srai x17, x17, 32       // ............................................................................................*......
        // addi x17, x17, 256      // .............................................................................................*.....
        // mulh x17, x17, x16      // ..............................................................................................*....
        // sub x27, x25, x17       // ..................................................................................................*
        // add x25, x25, x17       // ..................................................................................................*
        // mul  x17, x14, x31      // ..............................................................................*....................
        // srai x17, x17, 32       // ..................................................................................*................
        // addi x17, x17, 256      // .........................................................................................*.........
        // mulh x17, x17, x16      // ..........................................................................................*........
        // sub x14, x12, x17       // ................................................................................................*..
        // add x12, x12, x17       // ..............................................................................................*....
        // mul  x17, x15, x31      // ......................................................................................*............
        // srai x17, x17, 32       // ..........................................................................................*........
        // addi x17, x17, 256      // ...........................................................................................*.......
        // mulh x17, x17, x16      // ............................................................................................*......
        // sub x15, x13, x17       // ................................................................................................*..
        // add x13, x13, x17       // .................................................................................................*.

        end_label:

    // layer 4
    ct_bfu s0,  s1,  tp, a6, a7
    ct_bfu s2,  s3,  ra, a6, a7
    ld a7, 9*8(a1)
    ct_bfu s4,  s5,  a7, a6, a7
    ld a7, 10*8(a1)
    ct_bfu s6,  s7,  a7, a6, a7
    ld a7, 11*8(a1)
    ct_bfu s8,  s9,  a7, a6, a7
    ld a7, 12*8(a1)
    ct_bfu s10, s11, a7, a6, a7
    ld a7, 13*8(a1)
    ct_bfu a2,  a3,  a7, a6, a7
    ld a7, 14*8(a1)
    ct_bfu a4,  a5,  a7, a6, a7

    store_coeffs a0, 16, 4
  addi gp, gp, -1
  bge gp, zero, ntt_8l_rv64im_loop1
  addi a1, a1, 15*8
  // LAYER 5+6+7+8
  addi gp, x0, 16
  ntt_8l_rv64im_loop2:
    load_coeffs a0, 1, 4
    ld t0, 0*8(a1)
    ld t1, 1*8(a1)
    ld t2, 2*8(a1)
    ld t3, 3*8(a1)
    ld t4, 4*8(a1)
    ld t5, 5*8(a1)
    ld t6, 6*8(a1)
    ld tp, 7*8(a1)
    ld ra, 8*8(a1)
    // layer 5
    ct_bfu s0, s8,  t0, a6, a7
    ct_bfu s1, s9,  t0, a6, a7
    ct_bfu s2, s10, t0, a6, a7
    ct_bfu s3, s11, t0, a6, a7
    ct_bfu s4, a2,  t0, a6, a7
    ct_bfu s5, a3,  t0, a6, a7
    ct_bfu s6, a4,  t0, a6, a7
    ct_bfu s7, a5,  t0, a6, a7
    // layer 6
    ct_bfu s0,  s4, t1, a6, a7
    ct_bfu s1,  s5, t1, a6, a7
    ct_bfu s2,  s6, t1, a6, a7
    ct_bfu s3,  s7, t1, a6, a7
    ct_bfu s8,  a2, t2, a6, a7
    ct_bfu s9,  a3, t2, a6, a7
    ct_bfu s10, a4, t2, a6, a7
    ct_bfu s11, a5, t2, a6, a7
    // layer 7
    ct_bfu s0, s2,  t3, a6, a7
    ct_bfu s1, s3,  t3, a6, a7
    ct_bfu s4, s6,  t4, a6, a7
    ct_bfu s5, s7,  t4, a6, a7
    ct_bfu s8, s10, t5, a6, a7
    ct_bfu s9, s11, t5, a6, a7
    ct_bfu a2, a4,  t6, a6, a7
    ct_bfu a3, a5,  t6, a6, a7
    // layer 8
    ct_bfu s0,  s1,  tp, a6, a7
    ct_bfu s2,  s3,  ra, a6, a7
    ld a7, 9*8(a1)
    ct_bfu s4,  s5,  a7, a6, a7
    ld a7, 10*8(a1)
    ct_bfu s6,  s7,  a7, a6, a7
    ld a7, 11*8(a1)
    ct_bfu s8,  s9,  a7, a6, a7
    ld a7, 12*8(a1)
    ct_bfu s10, s11, a7, a6, a7
    ld a7, 13*8(a1)
    ct_bfu a2,  a3,  a7, a6, a7
    ld a7, 14*8(a1)
    ct_bfu a4,  a5,  a7, a6, a7
    store_coeffs a0, 1, 4
    addi a0, a0, 16*4
    addi a1, a1, 15*8
  addi gp, gp, -1
  bne gp, zero, ntt_8l_rv64im_loop2
  restore_regs
  addi sp, sp, 8*15
  ret

// todo: range analysis
// |input| < kq; |output| < 0.5q
// API: a0: poly, a1: 64-bit twiddle ptr; a6: q<<32; a7: tmp; gp: loop;
// s0-s11, a2-a5: 16 coeffs;
// 16+2+1+1=20 regs;
// 8 twiddle factors: can be preloaded; t0-t6, tp; ra: tmp zeta.
.global intt_8l_rv64im
.align 2
intt_8l_rv64im:
  addi sp, sp, -8*15
  save_regs
  li a6, q32
  // LAYER 8+7+6+5
  addi gp, x0, 16
  intt_8l_rv64im_loop1:
    load_coeffs a0, 1, 4
    ld t0, 0*8(a1)
    ld t1, 1*8(a1)
    ld t2, 2*8(a1)
    ld t3, 3*8(a1)
    ld t4, 4*8(a1)
    ld t5, 5*8(a1)
    ld t6, 6*8(a1)
    ld tp, 7*8(a1)
    // layer 8
    gs_bfu s0,  s1, t0, a6, a7
    gs_bfu s2,  s3, t1, a6, a7
    gs_bfu s4,  s5, t2, a6, a7
    gs_bfu s6,  s7, t3, a6, a7
    gs_bfu s8,  s9, t4, a6, a7
    gs_bfu s10,s11, t5, a6, a7
    gs_bfu a2,  a3, t6, a6, a7
    gs_bfu a4,  a5, tp, a6, a7
    // layer 7
    ld ra, 8*8(a1)
    gs_bfu s0, s2,  ra, a6, a7
    gs_bfu s1, s3,  ra, a6, a7
    ld ra, 9*8(a1)
    gs_bfu s4, s6,  ra, a6, a7
    gs_bfu s5, s7,  ra, a6, a7
    ld ra, 10*8(a1)
    gs_bfu s8, s10, ra, a6, a7
    gs_bfu s9, s11, ra, a6, a7
    ld ra, 11*8(a1)
    gs_bfu a2, a4,  ra, a6, a7
    gs_bfu a3, a5,  ra, a6, a7
    // layer 6
    ld ra, 12*8(a1)
    gs_bfu s0,  s4, ra, a6, a7
    gs_bfu s1,  s5, ra, a6, a7
    gs_bfu s2,  s6, ra, a6, a7
    gs_bfu s3,  s7, ra, a6, a7
    ld ra, 13*8(a1)
    gs_bfu s8,  a2, ra, a6, a7
    gs_bfu s9,  a3, ra, a6, a7
    gs_bfu s10, a4, ra, a6, a7
    gs_bfu s11, a5, ra, a6, a7
    // layer 5
    ld ra, 14*8(a1)
    gs_bfu s0, s8,  ra, a6, a7
    gs_bfu s1, s9,  ra, a6, a7
    gs_bfu s2, s10, ra, a6, a7
    gs_bfu s3, s11, ra, a6, a7
    gs_bfu s4, a2,  ra, a6, a7
    gs_bfu s5, a3,  ra, a6, a7
    gs_bfu s6, a4,  ra, a6, a7
    gs_bfu s7, a5,  ra, a6, a7
    store_coeffs a0, 1, 4
    addi a0, a0, 16*4
    addi a1, a1, 8*15
  addi gp, gp, -1
  bne gp, zero, intt_8l_rv64im_loop1
  addi a0, a0, -256*4
  // LAYER 4+3+2+1
  ld t0, 0*8(a1)
  ld t1, 1*8(a1)
  ld t2, 2*8(a1)
  ld t3, 3*8(a1)
  ld t4, 4*8(a1)
  ld t5, 5*8(a1)
  ld t6, 6*8(a1)
  ld tp, 7*8(a1)
  addi a0, a0, 16*4
  addi gp, x0, 15
  intt_8l_rv64im_loop2:
    addi a0, a0, -4
    load_coeffs a0, 16, 4
    // layer 4
    gs_bfu s0,  s1,  t0, a6, a7
    gs_bfu s2,  s3,  t1, a6, a7
    gs_bfu s4,  s5,  t2, a6, a7
    gs_bfu s6,  s7,  t3, a6, a7
    gs_bfu s8,  s9,  t4, a6, a7
    gs_bfu s10, s11, t5, a6, a7
    gs_bfu a2,  a3,  t6, a6, a7
    gs_bfu a4,  a5,  tp, a6, a7
    // layer 3
    ld ra, 8*8(a1)
    gs_bfu s0, s2,  ra, a6, a7
    gs_bfu s1, s3,  ra, a6, a7
    ld ra, 9*8(a1)
    gs_bfu s4, s6,  ra, a6, a7
    gs_bfu s5, s7,  ra, a6, a7
    ld ra, 10*8(a1)
    gs_bfu s8, s10, ra, a6, a7
    gs_bfu s9, s11, ra, a6, a7
    ld ra, 11*8(a1)
    gs_bfu a2, a4,  ra, a6, a7
    gs_bfu a3, a5,  ra, a6, a7
    // layer 2
    ld ra, 12*8(a1)
    gs_bfu s0,  s4, ra, a6, a7
    gs_bfu s1,  s5, ra, a6, a7
    gs_bfu s2,  s6, ra, a6, a7
    gs_bfu s3,  s7, ra, a6, a7
    ld ra, 13*8(a1)
    gs_bfu s8,  a2, ra, a6, a7
    gs_bfu s9,  a3, ra, a6, a7
    gs_bfu s10, a4, ra, a6, a7
    gs_bfu s11, a5, ra, a6, a7
    // layer 1
    ld ra, 14*8(a1)
    gs_bfu s0, s8,  ra, a6, a7
    gs_bfu s1, s9,  ra, a6, a7
    gs_bfu s2, s10, ra, a6, a7
    gs_bfu s3, s11, ra, a6, a7
    gs_bfu s4, a2,  ra, a6, a7
    gs_bfu s5, a3,  ra, a6, a7
    gs_bfu s6, a4,  ra, a6, a7
    gs_bfu s7, a5,  ra, a6, a7
    ld ra, 15*8(a1)
    plant_mul_const_inplace a6, ra, s0
    plant_mul_const_inplace a6, ra, s1
    plant_mul_const_inplace a6, ra, s2
    plant_mul_const_inplace a6, ra, s3
    plant_mul_const_inplace a6, ra, s4
    plant_mul_const_inplace a6, ra, s5
    plant_mul_const_inplace a6, ra, s6
    plant_mul_const_inplace a6, ra, s7
    store_coeffs a0, 16, 4
  addi gp, gp, -1
  bge gp, zero, intt_8l_rv64im_loop2
  restore_regs
  addi sp, sp, 8*15
  ret

// void poly_basemul_8l_init_rv64im(int64_t r[256], const int32_t a[256], const int32_t b[256])
.globl poly_basemul_8l_init_rv64im
.align 2
poly_basemul_8l_init_rv64im:
    addi sp, sp, -8*15
    save_regs
    // loop control
    li gp, 32*8*8
    add gp, gp, a0
poly_basemul_8l_init_rv64im_looper:
    lw t0, 0*4(a1) // a0
    lw s0, 0*4(a2) // b0
    lw t1, 1*4(a1) // a1
    lw s1, 1*4(a2) // b1
    lw t2, 2*4(a1) // a2
    lw s2, 2*4(a2) // b2
    lw t3, 3*4(a1) // a3
    lw s3, 3*4(a2) // b3
    mul s8, t0, s0
    mul s10,t1, s1
    mul a3, t2, s2
    mul a5, t3, s3
    sd s8, 0*8(a0)
    sd s10,1*8(a0)
    sd a3, 2*8(a0)
    sd a5, 3*8(a0)
    lw t4, 4*4(a1) // a4
    lw s4, 4*4(a2) // b4
    lw t5, 5*4(a1) // a5
    lw s5, 5*4(a2) // b5
    lw t6, 6*4(a1) // a6
    lw s6, 6*4(a2) // b6
    lw tp, 7*4(a1) // a7
    lw s7, 7*4(a2) // b7
    mul s8, t4, s4
    mul s10,t5, s5
    mul a3, t6, s6
    mul a5, tp, s7
    sd s8, 4*8(a0)
    sd s10,5*8(a0)
    sd a3, 6*8(a0)
    sd a5, 7*8(a0)
    // loop control
    addi a0, a0, 8*8
    addi a1, a1, 4*8
    addi a2, a2, 4*8
    bne gp, a0, poly_basemul_8l_init_rv64im_looper
    restore_regs
    addi sp, sp, 8*15
    ret

// void poly_basemul_8l_acc_rv64im(int64_t r[256], const int32_t a[256], const int32_t b[256])
.globl poly_basemul_8l_acc_rv64im
.align 2
poly_basemul_8l_acc_rv64im:
    addi sp, sp, -8*15
    save_regs
    // loop control
    li gp, 32*8*8
    add gp, gp, a0
poly_basemul_8l_acc_rv64im_looper:
    lw t0, 0*4(a1) // a0
    lw s0, 0*4(a2) // b0
    lw t1, 1*4(a1) // a1
    lw s1, 1*4(a2) // b1
    lw t2, 2*4(a1) // a2
    lw s2, 2*4(a2) // b2
    lw t3, 3*4(a1) // a3
    lw s3, 3*4(a2) // b3
    ld s9, 0*8(a0)
    ld s11,1*8(a0)
    ld a4, 2*8(a0)
    ld a6, 3*8(a0)
    mul s8, t0, s0
    mul s10,t1, s1
    mul a3, t2, s2
    mul a5, t3, s3
    add s8, s8, s9
    add s10,s10,s11
    add a3, a3, a4
    add a5, a5, a6
    sd s8, 0*8(a0)
    sd s10,1*8(a0)
    sd a3, 2*8(a0)
    sd a5, 3*8(a0)
    lw t4, 4*4(a1) // a4
    lw s4, 4*4(a2) // b4
    lw t5, 5*4(a1) // a5
    lw s5, 5*4(a2) // b5
    lw t6, 6*4(a1) // a6
    lw s6, 6*4(a2) // b6
    lw tp, 7*4(a1) // a7
    lw s7, 7*4(a2) // b7
    ld s9, 4*8(a0)
    ld s11,5*8(a0)
    ld a4, 6*8(a0)
    ld a6, 7*8(a0)
    mul s8, t4, s4
    mul s10,t5, s5
    mul a3, t6, s6
    mul a5, tp, s7
    add s8, s8, s9
    add s10,s10,s11
    add a3, a3, a4
    add a5, a5, a6
    sd s8, 4*8(a0)
    sd s10,5*8(a0)
    sd a3, 6*8(a0)
    sd a5, 7*8(a0)
    // loop control
    addi a0, a0, 8*8
    addi a1, a1, 4*8
    addi a2, a2, 4*8
    bne gp, a0, poly_basemul_8l_acc_rv64im_looper
    restore_regs
    addi sp, sp, 8*15
    ret

// void poly_basemul_8l_acc_end_rv64im(int32_t r[256], const int32_t a[256], const int32_t b[256], int64_t r_double[256])
.globl poly_basemul_8l_acc_end_rv64im
.align 2
poly_basemul_8l_acc_end_rv64im:
    addi sp, sp, -8*15
    save_regs
    li a4, q32
    li a5, qinv
    // loop control
    li gp, 64*4*4
    add gp, gp, a0
poly_basemul_8l_acc_end_rv64im_looper:
    // a0-a3
    lw s0, 0*4(a1)
    lw s1, 1*4(a1)
    lw s2, 2*4(a1)
    lw s3, 3*4(a1)
    // b0-b4
    lw t0, 0*4(a2)
    lw t1, 1*4(a2)
    lw t2, 2*4(a2)
    lw t3, 3*4(a2)
    // r_double[0-3]
    ld s4, 0*8(a3)
    ld s6, 1*8(a3)
    ld s8, 2*8(a3)
    ld s10,3*8(a3)
    // a0b0-a3b3
    mul t4, s0, t0
    mul a6, s1, t1
    mul t6, s2, t2
    mul a7, s3, t3
    // accumulate
    add s4, s4, t4
    add s6, s6, a6
    add s8, s8, t6
    add s10,s10,a7
    // rdc
    plant_red_x4 a4, a5, s4, s6, s8, s10
    // store results
    sw s4, 0*4(a0)
    sw s6, 1*4(a0)
    sw s8, 2*4(a0)
    sw s10,3*4(a0)
    // loop control
    addi a0, a0, 4*4
    addi a1, a1, 4*4
    addi a2, a2, 4*4
    addi a3, a3, 8*4
    bne gp, a0, poly_basemul_8l_acc_end_rv64im_looper
    restore_regs
    addi sp, sp, 8*15
    ret

// void poly_basemul_8l_rv64im(int32_t r[256], const int32_t a[256], const int32_t b[256])
.globl poly_basemul_8l_rv64im
.align 2
poly_basemul_8l_rv64im:
    addi sp, sp, -8*15
    save_regs
    li a4, q32
    li a5, qinv
    // loop control
    li gp, 64*4*4
    add gp, gp, a0
poly_basemul_8l_rv64im_looper:
    // a0-a3
    lw s0, 0*4(a1)
    lw s1, 1*4(a1)
    lw s2, 2*4(a1)
    lw s3, 3*4(a1)
    // b0-b4
    lw t0, 0*4(a2)
    lw t1, 1*4(a2)
    lw t2, 2*4(a2)
    lw t3, 3*4(a2)
    // a0b0-a3b3
    mul s4, s0, t0
    mul s6, s1, t1
    mul s8, s2, t2
    mul s10,s3, t3
    plant_red_x4 a4, a5, s4, s6, s8, s10
    // store results
    sw s4, 0*4(a0)
    sw s6, 1*4(a0)
    sw s8, 2*4(a0)
    sw s10,3*4(a0)
    // loop control
    addi a0, a0, 4*4
    addi a1, a1, 4*4
    addi a2, a2, 4*4
    bne gp, a0, poly_basemul_8l_rv64im_looper
    restore_regs
    addi sp, sp, 8*15
    ret

// void poly_reduce_rv64im(int32_t in[256]);
.globl poly_reduce_rv64im
.align 2
poly_reduce_rv64im:
    li a1, 4194304  // 1<<22
    li a2, q
    addi a3, a0, 64*4*4
poly_reduce_rv64im_loop:
    lw a4, 0*4(a0)
    lw a5, 1*4(a0)
    lw a6, 2*4(a0)
    lw a7, 3*4(a0)
    add  t0, a4, a1
    add  t1, a5, a1
    add  t2, a6, a1
    add  t3, a7, a1
    srai t0, t0, 23
    srai t1, t1, 23
    srai t2, t2, 23
    srai t3, t3, 23
    mul  t0, t0, a2
    mul  t1, t1, a2
    mul  t2, t2, a2
    mul  t3, t3, a2
    sub  a4, a4, t0
    sub  a5, a5, t1
    sub  a6, a6, t2
    sub  a7, a7, t3
    sw a4, 0*4(a0)
    sw a5, 1*4(a0)
    sw a6, 2*4(a0)
    sw a7, 3*4(a0)
    addi a0, a0, 4*4
    bne a3, a0, poly_reduce_rv64im_loop
    ret
